{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = 423\n",
    "\n",
    "inputFile = '../data/居住地信息/' + str(DATE).rjust(4, '0') + '.txt'\n",
    "\n",
    "allDistricts = ['浦东新区', '虹口区', '闵行区', '徐汇区', '黄浦区', '嘉定区', '静安区',\n",
    "                '杨浦区', '宝山区', '奉贤区', '松江区', '崇明区', '青浦区', '金山区', '长宁区', '普陀区']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取&整理inputFile，存入today: list中\n",
    "\n",
    "print('parsing',inputFile)\n",
    "today = []\n",
    "# 3/9 ～ 3/17\n",
    "'''\n",
    "with open(inputFile) as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            line = re.findall(\"居住于(.+)\",line)[0]\n",
    "        except:\n",
    "            continue\n",
    "        line = line.split('\\n')[0]\n",
    "        line = line.split('（')[0]\n",
    "        line = line.split('(')[0]\n",
    "        \n",
    "        today.append(line)\n",
    "'''\n",
    "\n",
    "\n",
    "# 3/18及之后\n",
    "currDistrict = \"\"\n",
    "with open(inputFile) as f:\n",
    "    for line in f:\n",
    "        line = line.split('\\n')[0]\n",
    "        line = line.split('（')[0]\n",
    "        line = line.split('(')[0]\n",
    "        line = line.split('，')[0]\n",
    "        \n",
    "        if line in allDistricts:\n",
    "            currDistrict = line\n",
    "            continue\n",
    "        today.append(currDistrict+line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存整理后得到的today\n",
    "\n",
    "np.save(\"../data/居住地信息_processed/\"+inputFile.split('/')[-1].split(sep='.')[0]+\".npy\", today)\n",
    "print(\"save to\", \"../data/居住地信息_proacessed/\"+inputFile.split('/')[-1].split(sep='.')[0]+\".npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 all_address.npy\n",
    "\n",
    "try:\n",
    "    all_addresses = list(np.load('../data/居住地信息_processed/all_addresses.npy'))\n",
    "    for i in range(len(all_addresses)):\n",
    "        all_addresses[i] = all_addresses[i].split('（')[0]\n",
    "    print(\"read from all_addresses.npy\")\n",
    "except:\n",
    "    print(\"There's no all_addresses.npy. Initializing a new one...\")\n",
    "    all_addresses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将新地址加入到 all_address 中，更新 all_address.npy\n",
    "\n",
    "print(\"updating all_addresses.npy...\")\n",
    "prev = len(all_addresses)\n",
    "\n",
    "all_addresses_new = all_addresses + today\n",
    "all_addresses_new = sorted(list(set(all_addresses_new)))\n",
    "\n",
    "new_address = list(set(all_addresses_new) - set(all_addresses))\n",
    "\n",
    "for district in allDistricts:\n",
    "    if district in all_addresses_new:\n",
    "        all_addresses_new.remove(district)\n",
    "        \n",
    "curr = len(all_addresses_new)\n",
    "assert len(new_address) == curr-prev\n",
    "print(\"added\", curr-prev, 'elements')\n",
    "all_addresses = all_addresses_new\n",
    "np.save('../data/居住地信息_processed/all_addresses.npy', all_addresses)\n",
    "print('done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 estate_info.csv\n",
    "\n",
    "try:\n",
    "    estate_info = pd.read_csv('../data/daily_info/estate_info_'+str(DATE-1).rjust(4, '0')+'.csv')\n",
    "    print('reading from', './data/estate_info_'+str(DATE-1).rjust(4, '0')+'.csv')\n",
    "\n",
    "except:\n",
    "    print('cannot find ../data/daily_info/estate_info_'+str(DATE).rjust(4, '0')+'.csv  Initializing a new estate_info...')\n",
    "    estate_info = pd.DataFrame(columns=['address', 'lon', 'lat', 'name', 'poiType', 'city', 'district', 'town', 'encode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据address查询gps坐标(BD09)，然后根据gps坐标获取对应的POI名称，类型，所属区县，街道\n",
    "\n",
    "# myAK = 'TnG2vjIajzrD4px4pyrod13ns2qTGPOu'\n",
    "myAK = '27gAPLcAkOCzK6NGQVyRyMQYPGjRBa9F'\n",
    "\n",
    "if len(new_address) > 0:\n",
    "    new_estate_info = pd.DataFrame(new_address, columns=['address'])\n",
    "\n",
    "    pandarallel.initialize(progress_bar=True, nb_workers=64)\n",
    "    new_estate_info[['city', 'district', 'town', 'name', 'poiType', 'lon_wgs', 'lat_wgs','source', 'confidence']] = new_estate_info.parallel_apply(lambda x: GD_GPS_TownInfo(x.address), axis=1, result_type='expand')\n",
    "\n",
    "\n",
    "    # pandarallel.initialize(progress_bar=True,nb_workers=15)\n",
    "    # new_estate_info[['lon', 'lat']] = new_estate_info.parallel_apply(lambda x: getGPS(x['address'], myAK), axis=1, result_type='expand')\n",
    "    # pandarallel.initialize(progress_bar=True,nb_workers=22)\n",
    "    # new_estate_info[['lon_gd', 'lat_gd']] = new_estate_info.parallel_apply(lambda x: GD_GPS(x['address']), axis=1, result_type='expand')\n",
    "\n",
    "    # pandarallel.initialize(progress_bar=True,nb_workers=15)\n",
    "    # new_estate_info[['name', 'poiType', 'city', 'district', 'town']] = new_estate_info.parallel_apply(lambda x: getTownInfo(x['lon'], x['lat'], myAK), axis=1, result_type='expand')\n",
    "    # pandarallel.initialize(progress_bar=True,nb_workers=22)\n",
    "    # new_estate_info[['name_gd', 'city_gd', 'district_gd', 'town_gd']] = new_estate_info.parallel_apply(lambda x: GD_townInfo(x['lon_gd'], x['lat_gd']), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将BD09坐标系转换成wgs\n",
    "\n",
    "# estate_info[['lon_wgs', 'lat_wgs']] = estate_info.parallel_apply(lambda x: bd09_to_wgs84(x['lon'], x['lat']), axis=1, result_type='expand')\n",
    "\n",
    "# if len(new_address) > 0:\n",
    "#     pandarallel.initialize(progress_bar=False,nb_workers=60)\n",
    "#     new_estate_info[['lon_wgs', 'lat_wgs']] = new_estate_info.parallel_apply(lambda x: bd09_to_wgs84(x['lon'], x['lat']), axis=1, result_type='expand')\n",
    "#     new_estate_info.query(\"name == '-1'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并new_estate_info，estate_info\n",
    "\n",
    "if len(new_address) > 0:\n",
    "    estate_info = pd.concat([estate_info, new_estate_info])\n",
    "# estate_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成 gps encoder/decoder dict\n",
    "\n",
    "e_CNTs = []\n",
    "gps_encoder = {}\n",
    "gps_decoder = {}\n",
    "d_CNT = 1\n",
    "for d in allDistricts: # 区县编码\n",
    "    gps_encoder[d] = [str(d_CNT).rjust(2, '0')]\n",
    "    gps_decoder[str(d_CNT).rjust(2, '0')] = [d]\n",
    "    # print(d)\n",
    "    allTowns = estate_info.query('district == @d')['town'].unique()\n",
    "    town_encoder = {}\n",
    "    town_decoder = {}\n",
    "\n",
    "    t_CNT = 1\n",
    "    for t in allTowns: # 街道编码\n",
    "        town_encoder[t] = [str(t_CNT).rjust(2, '0')]\n",
    "        town_decoder[str(t_CNT).rjust(2, '0')] = [t]\n",
    "        allGPS = list(set(zip(estate_info.query('town == @t').lon_wgs, estate_info.query('town == @t').lat_wgs)))\n",
    "        estate_encode = {}\n",
    "        estate_decode = {}\n",
    "\n",
    "        e_CNT = 1\n",
    "        for e in allGPS: # gps编码\n",
    "            estate_encode[str(e)] = str(e_CNT).rjust(3, '0')\n",
    "            estate_decode[str(e_CNT).rjust(3, '0')] = e\n",
    "            e_CNT += 1\n",
    "        town_encoder[t].append(estate_encode)\n",
    "        town_decoder[str(t_CNT).rjust(2, '0')].append(estate_decode)\n",
    "\n",
    "        # if e_CNT >= 500:\n",
    "        #     print(t, e_CNT)\n",
    "\n",
    "            \n",
    "        e_CNTs.append(e_CNT)\n",
    "        t_CNT += 1\n",
    "\n",
    "    gps_encoder[d].append(town_encoder)\n",
    "    gps_decoder[str(d_CNT).rjust(2, '0')].append(town_decoder)\n",
    "\n",
    "    d_CNT += 1\n",
    "\n",
    "with open('../data/daily_info/gps_encoder.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(gps_encoder, fp, ensure_ascii=False)\n",
    "print('../data/daily_info/gps_encoder.json updated')\n",
    "\n",
    "with open('../data/daily_info/gps_decoder.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(gps_decoder, fp, ensure_ascii=False)\n",
    "print('../data/daily_info/gps_decoder.json updated')\n",
    "\n",
    "# max(e_CNTs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据gps_encoder添加编码信息\n",
    "pandarallel.initialize(progress_bar=False,nb_workers=60)\n",
    "estate_info['encode'] = estate_info.parallel_apply(lambda x : Encoder(x,gps_encoder), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除gps相同的地址，生成每日estate_info.csv, estate_info_simp.csv\n",
    "\n",
    "data = []\n",
    "for lon_wgs, lat_wgs in tqdm(set(zip(estate_info.lon_wgs, estate_info.lat_wgs))):\n",
    "    data.append(list(estate_info.query(\"lon_wgs == @lon_wgs & lat_wgs == @lat_wgs\").iloc[0, :].values))\n",
    "\n",
    "simp = pd.DataFrame(data, columns=estate_info.columns).sort_values('address')\n",
    "\n",
    "simp.to_csv('../data/daily_info/estate_info_'+str(DATE).rjust(4, '0')+'_simp.csv', index=False, encoding='utf_8_sig')\n",
    "print('../data/daily_info/estate_info_'+str(DATE).rjust(4, '0')+'_simp.csv generated')\n",
    "\n",
    "estate_info.to_csv('../data/daily_info/estate_info_'+str(DATE).rjust(4, '0')+'.csv',index=False, encoding='utf_8_sig')\n",
    "print('../data/daily_info/estate_info_'+str(DATE).rjust(4, '0')+'.csv generated')\n",
    "\n",
    "address_encode = {}\n",
    "address_decode = {}\n",
    "\n",
    "for item in list(zip(estate_info.address, estate_info.encode)):\n",
    "    a,e = item\n",
    "    address_encode[a] = e\n",
    "\n",
    "for item in list(zip(simp.address, simp.encode)):\n",
    "    a, e = item\n",
    "    address_decode[e] = a\n",
    "\n",
    "with open('../data/daily_info/address_encode.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(address_encode, fp, ensure_ascii=False)\n",
    "print(\"../data/daily_info/address_encode.json updated\")\n",
    "\n",
    "with open('../data/daily_info/address_decode.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(address_decode, fp, ensure_ascii=False)\n",
    "print(\"../data/daily_info/address_decode.json updated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(address_decode.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成每日 time_series.csv\n",
    "\n",
    "with open('../data/daily_info/address_decode.json') as fp:\n",
    "    address_decode = json.load(fp)\n",
    "\n",
    "with open('../data/daily_info/address_encode.json') as fp:\n",
    "    address_encode = json.load(fp)\n",
    "\n",
    "all_codes = address_decode.keys()\n",
    "\n",
    "time_series = pd.DataFrame(index=all_codes)\n",
    "\n",
    "file_dir = \"../data/居住地信息_processed\"\n",
    "listDir=os.listdir(file_dir)\n",
    "for fName in tqdm(listDir):\n",
    "    rslt = re.findall('\\d+\\.npy', fName)\n",
    "    if len(rslt) == 0:\n",
    "        continue\n",
    "    f = rslt[0]\n",
    "    date = f.split('.')[0]\n",
    "    today = list(np.load('../data/居住地信息_processed/' + f))\n",
    "    time_series.loc[:,date] = 0\n",
    "\n",
    "\n",
    "    for item in today:\n",
    "        item = item.split('（')[0]\n",
    "        if item in allDistricts:\n",
    "            continue\n",
    "        item = address_encode[item]\n",
    "        \n",
    "        time_series.loc[item,date] = 1\n",
    "\n",
    "\n",
    "\n",
    "time_series = time_series[sorted(time_series.columns)].fillna(0)\n",
    "\n",
    "time_series.to_csv('../data/daily_info/time_series_'+ str(DATE).rjust(4, '0')+'.csv')\n",
    "print('../data/daily_info/time_series_'+str(DATE).rjust(4, '0')+'.csv generated')\n",
    "\n",
    "time_series.to_csv('../data/CaseInfo_April/time_series.csv')\n",
    "print('../data/CaseInfo_April/time_series.csv generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新 estate_info_POI_category.json\n",
    "\n",
    "out_geojson_path = '../data/CaseInfo_April/estate_info_POI_category.json'\n",
    "\n",
    "features = []\n",
    "for row in simp.itertuples():\n",
    "    address = getattr(row, \"address\")\n",
    "    lon = getattr(row, \"lon_wgs\")\n",
    "    lat = getattr(row, \"lat_wgs\")\n",
    "    name = getattr(row, \"name\")\n",
    "    poiType = getattr(row, \"poiType\")\n",
    "    city = getattr(row, \"city\")\n",
    "    district = getattr(row, \"district\")\n",
    "    town = getattr(row, \"town\")\n",
    "    encode = getattr(row, \"encode\")\n",
    "\n",
    "    features.append({\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [lon, lat]\n",
    "        },\n",
    "        \"properties\": {\n",
    "            'address': address,\n",
    "            'name': name,\n",
    "            'encode': encode,\n",
    "            'city': city,\n",
    "            'district': district,\n",
    "            'town': town,\n",
    "            'poiType': poiType\n",
    "\n",
    "        }\n",
    "    })\n",
    "\n",
    "save_data = {\"type\": \"FeatureCollection\", \"features\": features}\n",
    "with open(out_geojson_path, \"w\", encoding='utf-8') as f:\n",
    "    f.write(json.dumps(save_data, ensure_ascii=False, indent=4, separators=(',', ':') ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estate_info[['address','city','district','town','name','poiType','source','confidence','encode']].to_csv('/home/shengyuan/SH-COVID19/source/data/CaseInfo_April/estate_info_pub.csv')\n",
    "print(\"estate_info_pub generated\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d2dc40c0883af236c1484f75698ae64e2b80d1c461a271144b9db85068541f5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
